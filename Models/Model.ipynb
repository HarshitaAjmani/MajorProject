{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating images for the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating images for the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24045 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('D:/SRM/Assingment/8Sem/code/2nd_git/two/dataSetHarshu/trainingData',                                \n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 10,\n",
    "                                                 color_mode = 'grayscale',                                \n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6726 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "vali_set = vali_datagen.flow_from_directory('D:/SRM/Assingment/8Sem/code/2nd_git/two/dataSetHarshu/validationData',\n",
    "                                            target_size = (128, 128),                                  \n",
    "                                            batch_size = 10,        \n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Pyython_Harshu\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.keras.models.Sequential() \n",
    "# It creates a new object, which is a linear stack of layers. This type of model is often used for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                                     kernel_size=3, \n",
    "                                     padding=\"same\", \n",
    "                                     activation=\"relu\", \n",
    "                                     input_shape=[128, 128, 1]))\n",
    "\n",
    "#padding ensures that the output feature map has the same spatial dimensions as the input volume by padding zeros to the input.\n",
    "#ReLU is commonly used in deep learning models for introducing non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Pyython_Harshu\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
    "                                         strides=2, \n",
    "                                         padding='valid'))\n",
    "#pool size 2x2 window\n",
    "#A stride of 2 means that the pooling window moves by 2 pixels in both the horizontal and vertical directions.\n",
    "#Max pooling is a downsampling operation commonly used in convolutional neural networks (CNNs) to reduce the spatial dimensions of the input volume, \n",
    "#leading to a reduction in the number of parameters and computation in the network. It helps in controlling overfitting and improving the network's ability to learn relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Conv2D(filters=32, \n",
    "                                      kernel_size=3, \n",
    "                                      padding=\"same\", \n",
    "                                      activation=\"relu\"))\n",
    "\n",
    "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
    "                                         strides=2, \n",
    "                                         padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Flatten())\n",
    "#This layer is used to flatten the input data into a one-dimensional array. \n",
    "# It converts the multi-dimensional feature maps generated by the\n",
    "#convolutional layers into a one-dimensional vector,\n",
    "# which can be fed into the fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each Dense layer contains units neurons. \n",
    "classifier.add(tf.keras.layers.Dense(units=128, \n",
    "                                     activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.40))\n",
    "classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.40))\n",
    "classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dense(units=27, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "#Dropout is a regularization technique used to prevent overfitting in neural networks. It randomly sets a fraction of input units to zero during training, which helps to prevent the model from relying too heavily on any individual neurons. The parameter 0.40 specifies the fraction of units to drop during training, in this case, 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Pyython_Harshu\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', \n",
    "                   loss = 'categorical_crossentropy', \n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4194432   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                12384     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4224347 (16.11 MB)\n",
      "Trainable params: 4224347 (16.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:From c:\\Pyython_Harshu\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Pyython_Harshu\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2405/2405 [==============================] - 829s 343ms/step - loss: 1.4829 - accuracy: 0.5389 - val_loss: 0.1128 - val_accuracy: 0.9683\n",
      "Epoch 2/25\n",
      "2405/2405 [==============================] - 229s 95ms/step - loss: 0.4499 - accuracy: 0.8503 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
      "Epoch 3/25\n",
      "2405/2405 [==============================] - 232s 97ms/step - loss: 0.2936 - accuracy: 0.9069 - val_loss: 0.0272 - val_accuracy: 0.9917\n",
      "Epoch 4/25\n",
      "2405/2405 [==============================] - 235s 97ms/step - loss: 0.2233 - accuracy: 0.9304 - val_loss: 0.0245 - val_accuracy: 0.9926\n",
      "Epoch 5/25\n",
      "2405/2405 [==============================] - 239s 99ms/step - loss: 0.1866 - accuracy: 0.9407 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
      "Epoch 6/25\n",
      "2405/2405 [==============================] - 235s 98ms/step - loss: 0.1559 - accuracy: 0.9519 - val_loss: 0.0079 - val_accuracy: 0.9976\n",
      "Epoch 7/25\n",
      "2405/2405 [==============================] - 241s 100ms/step - loss: 0.1398 - accuracy: 0.9581 - val_loss: 0.0162 - val_accuracy: 0.9945\n",
      "Epoch 8/25\n",
      "2405/2405 [==============================] - 229s 95ms/step - loss: 0.1274 - accuracy: 0.9611 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 9/25\n",
      "2405/2405 [==============================] - 229s 95ms/step - loss: 0.1165 - accuracy: 0.9655 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 10/25\n",
      "2405/2405 [==============================] - 237s 98ms/step - loss: 0.1044 - accuracy: 0.9687 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 11/25\n",
      "2405/2405 [==============================] - 239s 99ms/step - loss: 0.0999 - accuracy: 0.9696 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
      "Epoch 12/25\n",
      "2405/2405 [==============================] - 231s 96ms/step - loss: 0.0964 - accuracy: 0.9716 - val_loss: 0.0066 - val_accuracy: 0.9978\n",
      "Epoch 13/25\n",
      "2405/2405 [==============================] - 241s 100ms/step - loss: 0.0871 - accuracy: 0.9733 - val_loss: 0.0130 - val_accuracy: 0.9963\n",
      "Epoch 14/25\n",
      "2405/2405 [==============================] - 232s 97ms/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 15/25\n",
      "2405/2405 [==============================] - 241s 100ms/step - loss: 0.0830 - accuracy: 0.9757 - val_loss: 0.0191 - val_accuracy: 0.9945\n",
      "Epoch 16/25\n",
      "2405/2405 [==============================] - 229s 95ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
      "Epoch 17/25\n",
      "2405/2405 [==============================] - 235s 98ms/step - loss: 0.0691 - accuracy: 0.9802 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 18/25\n",
      "2405/2405 [==============================] - 230s 96ms/step - loss: 0.0695 - accuracy: 0.9799 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 19/25\n",
      "2405/2405 [==============================] - 239s 99ms/step - loss: 0.0674 - accuracy: 0.9816 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 20/25\n",
      "2405/2405 [==============================] - 240s 100ms/step - loss: 0.0645 - accuracy: 0.9819 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 21/25\n",
      "2405/2405 [==============================] - 231s 96ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 22/25\n",
      "2405/2405 [==============================] - 234s 97ms/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 23/25\n",
      "2405/2405 [==============================] - 238s 99ms/step - loss: 0.0637 - accuracy: 0.9822 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 24/25\n",
      "2405/2405 [==============================] - 232s 96ms/step - loss: 0.0633 - accuracy: 0.9827 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
      "Epoch 25/25\n",
      "2405/2405 [==============================] - 244s 101ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0031 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "pk = classifier.fit(training_set,\n",
    "                  epochs = 25,\n",
    "                  validation_data = vali_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Weights saved\n"
     ]
    }
   ],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"model_new.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Model Saved')\n",
    "classifier.save_weights('model_new_20epoch.h5')\n",
    "print('Weights saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3576 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('D:/SRM/Assingment/8Sem/code/2nd_git/two/dataSetHarshu/testingData',\n",
    "                                            target_size = (128, 128),                                  \n",
    "                                            batch_size = 10,        \n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical',\n",
    "                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 12s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict = classifier.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_9056\\1022196031.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred=classifier.predict_generator(test_set,steps=STEP_SIZE_TEST,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_set.batch_size\n",
    "test_set.reset()\n",
    "pred=classifier.predict_generator(test_set,steps=STEP_SIZE_TEST,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576, 27)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994407158836689\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(test_predict, axis=-1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_set.classes\n",
    "\n",
    "print(accuracy_score(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true_labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
